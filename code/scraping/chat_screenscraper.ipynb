{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\Donovan\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getChannels(url):\n",
    "    driver.get(url)\n",
    "    content = driver.page_source\n",
    "    soup = BeautifulSoup(content)\n",
    "    channels = []\n",
    "\n",
    "    num_pages = math.ceil(int(soup.find('p',{'class':'pagination'}).text.split(\" \")[0][1:].replace(\",\",\"\")) / 10)\n",
    "        \n",
    "    for page in range(1, num_pages+1):\n",
    "        driver.get(url+\"?&page=\"+str(page))\n",
    "        content = driver.page_source\n",
    "        soup = BeautifulSoup(content)\n",
    "        for _ in soup.findAll('a',href=re.compile(\"\\/discord\\/channel\\/.+\")):\n",
    "            channels.append(_['href'])\n",
    "    \n",
    "    return channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://discordleaks.unicornriot.ninja\"\n",
    "channels = getChannels(url+'/discord/server/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCSV(url):\n",
    "    username=[] #Discord Username\n",
    "    user_id=[] #User ID from Unicorn Database (not the same as the Discord ID)\n",
    "    message_id=[] #Message ID from the Unicorn Database\n",
    "    avatar=[] #Avatar image link\n",
    "    timestamp=[] #Time of message posting\n",
    "    message=[] #Message content\n",
    "    \n",
    "    driver.get(url)\n",
    "    content = driver.page_source\n",
    "    soup = BeautifulSoup(content)\n",
    "    \n",
    "    num_pages = math.ceil(int(soup.find('p',{'class':'pagination'}).text.split(\" \")[0][1:].replace(\",\",\"\")) / 250)\n",
    "    \n",
    "    for page in range(1,num_pages+1):\n",
    "        driver.get(url+\"?&page=\"+str(page))\n",
    "        content = driver.page_source\n",
    "        soup = BeautifulSoup(content)\n",
    "        \n",
    "        chatroom = []\n",
    "        for _ in soup.findAll('div',{'class' : 'discord-message'}):\n",
    "            chatroom.append(_)\n",
    "\n",
    "        for _ in range(len(chatroom)):\n",
    "            message_id.append(chatroom[_].find('a', href=re.compile(\"\\/discord\\/view\\/.+\"))['href'][14:-7])\n",
    "            user_id.append(chatroom[_].find('a', href=re.compile(\"\\/discord\\/user\\/.+\"))['href'][14:])\n",
    "            avatar.append(chatroom[_].find('a', href=re.compile(\"\\/discord\\/user\\/.+\")).find('img')['src'])\n",
    "            username.append(chatroom[_].find('div', {'class':'discord-message-user-name'}).find('a').text[1:-1])\n",
    "            timestamp.append(chatroom[_].find('div', {'class':'discord-message-meta-items'}).find('span').text)\n",
    "            message.append(chatroom[_].find('div', {'class':'discord-message-content'}).text)\n",
    "    \n",
    "    df = pd.DataFrame({'Timestamp':timestamp,'User ID':user_id,'Username':username,'Avatar':avatar,'Message ID':message_id,'Message Content':message})\n",
    "    outname = soup.title.text.split(\" \")[0][1:]+\".csv\"\n",
    "    outdir = \"./\"+re.sub(r'[#\\/?!,]','',\"_\".join(soup.title.text[soup.title.text.find(\"in\\n\"):soup.title.text.find(\" | \")].split(\" \")[3:-2]))\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "    fullname = os.path.join(outdir, outname)    \n",
    "    df.to_csv(fullname, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in channels[50:100]:\n",
    "    current_url = url + _\n",
    "    createCSV(current_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
